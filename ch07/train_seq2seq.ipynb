{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import sequence\n",
        "from common.optimizer import Adam\n",
        "from common.trainer import Trainer\n",
        "from common.util import eval_seq2seq\n",
        "from seq2seq import Seq2seq\n",
        "from peeky_seq2seq import PeekySeq2seq\n",
        "\n",
        "\n",
        "# \ub370\uc774\ud130\uc14b \uc77d\uae30\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "# \uc785\ub825 \ubc18\uc804 \uc5ec\ubd80 \uc124\uc815 =============================================\n",
        "is_reverse = False  # True\n",
        "if is_reverse:\n",
        "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
        "# ================================================================\n",
        "\n",
        "# \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hideen_size = 128\n",
        "batch_size = 128\n",
        "max_epoch = 25\n",
        "max_grad = 5.0\n",
        "\n",
        "# \uc77c\ubc18 \ud639\uc740 \uc5ff\ubcf4\uae30(Peeky) \uc124\uc815 =====================================\n",
        "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
        "# model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
        "# ================================================================\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "acc_list = []\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(x_train, t_train, max_epoch=1,\n",
        "                batch_size=batch_size, max_grad=max_grad)\n",
        "\n",
        "    correct_num = 0\n",
        "    for i in range(len(x_test)):\n",
        "        question, correct = x_test[[i]], t_test[[i]]\n",
        "        verbose = i < 10\n",
        "        correct_num += eval_seq2seq(model, question, correct,\n",
        "                                    id_to_char, verbose, is_reverse)\n",
        "\n",
        "    acc = float(correct_num) / len(x_test)\n",
        "    acc_list.append(acc)\n",
        "    print('\uac80\uc99d \uc815\ud655\ub3c4 %.3f%%' % (acc * 100))\n",
        "\n",
        "# \uadf8\ub798\ud504 \uadf8\ub9ac\uae30\n",
        "x = np.arange(len(acc_list))\n",
        "plt.plot(x, acc_list, marker='o')\n",
        "plt.xlabel('\uc5d0\ud3ed')\n",
        "plt.ylabel('\uc815\ud655\ub3c4')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}