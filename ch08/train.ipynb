{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "sys.path.append('../ch07')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dataset import sequence\n",
        "from common.optimizer import Adam\n",
        "from common.trainer import Trainer\n",
        "from common.util import eval_seq2seq\n",
        "from attention_seq2seq import AttentionSeq2seq\n",
        "from ch07.seq2seq import Seq2seq\n",
        "from ch07.peeky_seq2seq import PeekySeq2seq\n",
        "\n",
        "\n",
        "# \ub370\uc774\ud130 \uc77d\uae30\n",
        "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
        "char_to_id, id_to_char = sequence.get_vocab()\n",
        "\n",
        "# \uc785\ub825 \ubb38\uc7a5 \ubc18\uc804\n",
        "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
        "\n",
        "# \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc124\uc815\n",
        "vocab_size = len(char_to_id)\n",
        "wordvec_size = 16\n",
        "hidden_size = 256\n",
        "batch_size = 128\n",
        "max_epoch = 10\n",
        "max_grad = 5.0\n",
        "\n",
        "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
        "\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "acc_list = []\n",
        "for epoch in range(max_epoch):\n",
        "    trainer.fit(x_train, t_train, max_epoch=1,\n",
        "                batch_size=batch_size, max_grad=max_grad)\n",
        "\n",
        "    correct_num = 0\n",
        "    for i in range(len(x_test)):\n",
        "        question, correct = x_test[[i]], t_test[[i]]\n",
        "        verbose = i < 10\n",
        "        correct_num += eval_seq2seq(model, question, correct,\n",
        "                                    id_to_char, verbose, is_reverse=True)\n",
        "\n",
        "    acc = float(correct_num) / len(x_test)\n",
        "    acc_list.append(acc)\n",
        "    print('\uc815\ud655\ub3c4 %.3f%%' % (acc * 100))\n",
        "\n",
        "\n",
        "model.save_params()\n",
        "\n",
        "# \uadf8\ub798\ud504 \uadf8\ub9ac\uae30\n",
        "x = np.arange(len(acc_list))\n",
        "plt.plot(x, acc_list, marker='o')\n",
        "plt.xlabel('\uc5d0\ud3ed')\n",
        "plt.ylabel('\uc815\ud655\ub3c4')\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}