{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# coding: utf-8\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.np import *  # import numpy as np\n",
        "from common.layers import Embedding\n",
        "from ch04.negative_sampling_layer import NegativeSamplingLoss\n",
        "\n",
        "\n",
        "class CBOW:\n",
        "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
        "        V, H = vocab_size, hidden_size\n",
        "\n",
        "        # \uac00\uc911\uce58 \ucd08\uae30\ud654\n",
        "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
        "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
        "\n",
        "        # \uacc4\uce35 \uc0dd\uc131\n",
        "        self.in_layers = []\n",
        "        for i in range(2 * window_size):\n",
        "            layer = Embedding(W_in)  # Embedding \uacc4\uce35 \uc0ac\uc6a9\n",
        "            self.in_layers.append(layer)\n",
        "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
        "\n",
        "        # \ubaa8\ub4e0 \uac00\uc911\uce58\uc640 \uae30\uc6b8\uae30\ub97c \ubc30\uc5f4\uc5d0 \ubaa8\uc740\ub2e4.\n",
        "        layers = self.in_layers + [self.ns_loss]\n",
        "        self.params, self.grads = [], []\n",
        "        for layer in layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "\n",
        "        # \uc778\uc2a4\ud134\uc2a4 \ubcc0\uc218\uc5d0 \ub2e8\uc5b4\uc758 \ubd84\uc0b0 \ud45c\ud604\uc744 \uc800\uc7a5\ud55c\ub2e4.\n",
        "        self.word_vecs = W_in\n",
        "\n",
        "    def forward(self, contexts, target):\n",
        "        h = 0\n",
        "        for i, layer in enumerate(self.in_layers):\n",
        "            h += layer.forward(contexts[:, i])\n",
        "        h *= 1 / len(self.in_layers)\n",
        "        loss = self.ns_loss.forward(h, target)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        dout = self.ns_loss.backward(dout)\n",
        "        dout *= 1 / len(self.in_layers)\n",
        "        for layer in self.in_layers:\n",
        "            layer.backward(dout)\n",
        "        return None\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}